{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbasecondabdc3294f84ff49e6a09ce26d18357ae8",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Embedding,LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数可以有如下几种类型可选: softmax，relu,tanh,sigmoid,hard_sigmoid,linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Dense(全连接层)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.core.Dense(units,activation = None,use_bias = True,kernel_initializer = \"glorot_uniform\",bias_initializer='zeros',kernel_regularizer = None,bias_regularizer =None,activity_regularizer =None,kernel_constraint=None,bias_constraint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## units: 大于0的整数，代表该层的输出维度\n",
    "## activation:激活函数\n",
    "## use_bias：是否使用偏置项\n",
    "## kernel_initializer:权值初始化方法\n",
    "## bias_initializer:权值初始化方法\n",
    "## kernel_regularizer:在权重上的设置正则项\n",
    "## bias_regularizer:在偏置向量上的正则项\n",
    "## activity_regularizer:施加在输出上的正则项\n",
    "## kernel_constrains:施加在权重上约束项\n",
    "## bias_constrains:施加在偏置上的约束项\n",
    "## input_dim:可以指定输入数据的维度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Conv2D 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.convolutional.ConV2D(filters,kernel_size,strides=(1,1),padding='valid',\n",
    "        data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',kernel_regularizer =None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,\n",
    "        bise_constraint = None,input_shape=((rows,cols,channels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filters: 卷积核数目(即输出维度)\n",
    "## kernel_size:单个整数或有两个整数构成的list/tuple,卷积核的宽度和长度,如单个整数，则表示在各个空间上维度都是相同长度\n",
    "## strides：单个整数或者由两个整数构成的list/tuple，为卷积的步长，如单个整数，则表示各个空间维度的相同步长，任何不为1的strides均与任何不为1的dilation_rate均不兼容\n",
    "## padding：补0策略，为\"valid\",\"same\"。\"valid\"代表只进行有效卷积，即对边界数据不处理,\"same\"代表保留边界外的卷积结果\n",
    "## activation:激活函数\n",
    "## dilation_rate: 单个整数或由两个个整数构成的list/tuple,指定dilated convolution中膨胀比例\n",
    "## data_format：字符串 \"channels_first\"或者\"channels_last\"之一，代表图像的通道维的位置\n",
    "## use_bias:布尔值，是否使用偏置项\n",
    "## kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers\n",
    "## bias_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers\n",
    "## kernel_regularizer：施加在权重上的正则项，为Regularizer对象\n",
    "## bias_regularizer：施加在偏置向量上的正则项，为Regularizer对象\n",
    "## activity_regularizer：施加在输出上的正则项，为Regularizer对象\n",
    "## kernel_constraints：施加在权重上的约束项，为Constraints对象\n",
    "## bias_constraints：施加在偏置上的约束项，为Constraints对象\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxPooling2D（池化层)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.pooling.MaxPooling2D(pool_size=(2,2),strides=None,padding='valid',data_format=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pool_size: 整数或长为2的整数，代表在两个方向(竖直,水平)上的下采样因子,如取(2,2)将使图片在两个维度上均变成原长的一半"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding(嵌入层)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.embedding.Embedding(input_dim,output_dim,embeddings_initializer='uniform',embedding_regularizer=None,activity_regularizer = None,embeddings_constraint=None,mask_zero=False,input_length=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入层将正整数(下标)转换为具有固定大小的向量,Embedding层只能作为模型第一层\n",
    "## input_dim：大或等于0的整数，字典长度，即输入数据最大下标+1，就是矩阵中的最大值\n",
    "## output_dim：大于0的整数，代表全连接嵌入的维度\n",
    "## embeddings_initializer: 嵌入矩阵的初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers\n",
    "## embeddings_regularizer: 嵌入矩阵的正则项，为Regularizer对象\n",
    "## embeddings_constraint: 嵌入矩阵的约束项，为Constraints对象\n",
    "## mask_zero：布尔值，确定是否将输入中的‘0’看作是应该被忽略的‘填充’（padding）值，该参数在使用递归层处理变长输入时有用。设置为True的话，模型中后续的层必须都支持masking，否则会抛出异常。如果该值为True，则下标0在字典中不可用，input_dim应设置为|vocabulary| + 2。\n",
    "## input_length：当输入序列的长度固定时，该值为其长度。如果要在该层后接Flatten层，然后接Dense层，则必须指定该参数，否则Dense层的输出维度无法自动推断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 比如要加入测试数据维度是[batch,200]的数据，数据类型为int型，最大不超过40000，期望输出为[batch,32*200]\n",
    "model.add(Embedding(input_dim=4000,output_dim = 32,input_length=200))  # 生成中间矩阵大小为[batch,200,32]\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(长短时记忆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.recurrent.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## units：输出维度\n",
    "## activation：激活函数，为预定义的激活函数名（参考激活函数）\n",
    "## recurrent_activation: 为循环步施加的激活函数（参考激活函数）\n",
    "## use_bias: 布尔值，是否使用偏置项\n",
    "## return_sequences：=True时，返回（None,timesteps,output_dim）;=False时，返回（None，output_dim）\n",
    "## kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers\n",
    "## recurrent_initializer：循环核的初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers\n",
    "## bias_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers\n",
    "## kernel_regularizer：施加在权重上的正则项，为Regularizer对象\n",
    "## bias_regularizer：施加在偏置向量上的正则项，为Regularizer对象\n",
    "## recurrent_regularizer：施加在循环核上的正则项，为Regularizer对象\n",
    "## activity_regularizer：施加在输出上的正则项，为Regularizer对象\n",
    "## kernel_constraints：施加在权重上的约束项，为Constraints对象\n",
    "## recurrent_constraints：施加在循环核上的约束项，为Constraints对象\n",
    "## bias_constraints：施加在偏置上的约束项，为Constraints对象\n",
    "## dropout：0~1之间的浮点数，控制输入线性变换的神经元断开比例\n",
    "## recurrent_dropout：0~1之间的浮点数，控制循环状态的线性变换的神经元断开比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编译模型compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer,loss,metrics =None,sample_weight_mode = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer：字符串（预定义优化器名）或优化器对象，参考优化器 \n",
    "## loss：字符串（预定义损失函数名）或目标函数，参考损失函数\n",
    "## metrics：列表，包含评估模型在训练和测试时的网络性能的指标，典型用法是metrics=['accuracy']\n",
    "## sample_weight_mode：如果你需要按时间步为样本赋权（2D权矩阵），将该值设为“temporal”。默认为“None”，代表按样本赋权（1D权）。在下面fit函数的解释中有相关的参考内容。\n",
    "## kwargs：使用TensorFlow作为后端请忽略该参数，若使用Theano作为后端，kwargs的值将会传递给 K.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None, validation_split=0.0,\n",
    "validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array## \n",
    "## y：标签，numpy array\n",
    "## batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。\n",
    "## epochs：整数，训练的轮数，每个epoch会把训练集轮一遍。\n",
    "## verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录\n",
    "## callbacks：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数\n",
    "## validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。\n",
    "## validation_data：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。\n",
    "## shuffle：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串“batch”，则是用来处理HDF5数据的特殊情况，它将在batch内部将数据打乱。\n",
    "## class_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）\n",
    "## sample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了sample_weight_mode='temporal'。\n",
    "## initial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。"
   ]
  }
 ]
}